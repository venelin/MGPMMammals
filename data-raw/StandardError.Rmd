---
title: "Untitled"
author: "Venelin Mitov"
date: "12/8/2018"
header-includes:
   - \usepackage{amsmath}
   - \usepackage{amssymb}
output: pdf_document
---
The correct approach has been known for decades (e.g., Jeffreys, 1931, p. 61, eq. 1) but to our knowledge, has never been applied in psychology. Let the error variance be the square of the standard error. Then the error variance of the averaged individual statistics is given by the mean error variance across participants divided by the number of participants. Formally, let $X_{ij}$ be the datum of participant i on the jth replication, i=1..n, j=1..m . We will denote $\hat{\mathbf{X}}_i$ a summary statistic computed from participant iâ€™s replications. Let further $\overline{\hat{\mathbf{X}}}$ denote the average of the summary statistics over all participants. We want to know the error variance of $\overline{\hat{\mathbf{X}}}$, noted $Var \Big(\,\overline{\hat{\mathbf{X}}} \,\Big)$, given the error variance of each participant, $Var \big( \hat{\mathbf{X}}_i \big)$. We have that
\[Var \Big(\, \overline{\hat{\mathbf{X}}} \,\Big)
= Var \left( \frac{1}{n} \sum_{i=1}^{n} \hat{\mathbf{X}}_i \right)
= \frac{1}{n^2} \;Var \left( \sum_{i=1}^{n} \hat{\mathbf{X}}_i \right)\] .

Because the variance of a sum of independent random variables is the sum of the variances, we can rewrite
\[\begin{split}
Var \Big(\, \overline{\hat{\mathbf{X}}} \,\Big)
&= \frac{1}{n^2} \; \sum_{i=1}^{n} Var \left( \hat{\mathbf{X}}_i \right)\\
&= \frac{1}{n} \; \overline{Var}\big( \hat{\mathbf{X}} \big)
\end{split}\]
where $\overline{Var} \big( \hat{\mathbf{X}} \big)$ is the averaged error variance across participants. The square root of the error variance is the standard error; hence
\[s \Big(\, \overline{\hat{\mathbf{X}}} \,\Big)
=\frac{1}{\sqrt{n}} \sqrt{ \overline{Var} \big( \hat{\mathbf{X}} \big) }
\]    .     (1)
The standard errors ${s} \big( \hat{\mathbf{X}}_i \big)$ are computed for each participant separately and squared to get the error variances $Var\big( \, \hat {\mathbf{X}_i } \,\big)$. Consequently, when standard deviations are required, they are within-subject standard deviations.
To go from a standard error to a $1-\alpha$ confidence interval, a multiplier is needed. When it is based on a degree of freedom, the degree of freedom is changed from $(n-1)$ to $n(m-1)$ to take into account the contribution of the $m$ replications.
